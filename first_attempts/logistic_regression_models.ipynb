{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Basic Overview\n",
    "The objective is to build a binary logistic regression model, to predict the survival chance on titanic, given person's relevant information.\n",
    "\n",
    "Comments/criticisms/appreciations are greatly accepted and appreciated. Do not be shy and send me an email at babinu@gmail.com !\n",
    "\n",
    "Source of data : https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../input/train.csv\")\n",
    "test_data = pd.read_csv(\"../input/test_data_processed_correct.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of functions to get complete data about survivors.\n",
    "\n",
    "def get_pid_to_survived_map(name_to_pid, name_to_survived_orig):\n",
    "    pid_to_survived = dict()\n",
    "    count = 0\n",
    "    for name in name_to_pid:\n",
    "        if name not in name_to_survived_orig:\n",
    "            count += 1\n",
    "            print(name, name_to_pid[name])\n",
    "        else:\n",
    "            pid = name_to_pid[name]\n",
    "            pid_to_survived[pid] = name_to_survived_orig[name]\n",
    "\n",
    "    pid_to_survived[911] = 1\n",
    "    pid_to_survived[925] = 0\n",
    "    pid_to_survived[927] = 0\n",
    "    pid_to_survived[941] = 1\n",
    "    pid_to_survived[944] = 1\n",
    "    pid_to_survived[996] = 1\n",
    "    pid_to_survived[1000] = 0\n",
    "    pid_to_survived[1036] = 0\n",
    "    pid_to_survived[1117] = 1\n",
    "    pid_to_survived[1136] = 0\n",
    "    pid_to_survived[1141] = 0\n",
    "    pid_to_survived[1154] = 1\n",
    "    pid_to_survived[1183] = 1\n",
    "    pid_to_survived[1196] = 1\n",
    "    pid_to_survived[1219] = 0\n",
    "    pid_to_survived[1225] = 1\n",
    "    pid_to_survived[1246] = 1\n",
    "    pid_to_survived[1259] = 0\n",
    "    pid_to_survived[1269] = 0\n",
    "    pid_to_survived[1276] = 0\n",
    "    pid_to_survived[1297] = 1\n",
    "    pid_to_survived[1300] = 1\n",
    "\n",
    "    return pid_to_survived\n",
    "\n",
    "def get_rel_map_from_csv_file(given_file, column1, column2):\n",
    "    given_file_data = pd.read_csv(given_file)\n",
    "    return dict(zip(given_file_data[column1], given_file_data[column2]))\n",
    "\n",
    "def get_complete_pid_to_survivorship_data(ext_file, kaggle_file):\n",
    "    # Raw data obtained from the following source :\n",
    "    # https://github.com/Geoyi/Cleaning-Titanic-Data/blob/master/titanic_original.csv\n",
    "    name_to_survived_orig = get_rel_map_from_csv_file(ext_file, 'name', 'survived')\n",
    "    name_to_pid = get_rel_map_from_csv_file(kaggle_file, 'Name', 'PassengerId')\n",
    "    pid_to_survived = get_pid_to_survived_map(name_to_pid, name_to_survived_orig)\n",
    "    return pid_to_survived\n",
    "\n",
    "# Example usage : dump_completed_survivorship_data_to_file(\"titanic_original.csv\", \"test.csv\", \"test2.csv\")\n",
    "def dump_completed_survivorship_data_to_file(ext_file, kaggle_file, new_output_file):\n",
    "    pid_to_survived = get_complete_pid_to_survivorship_data(ext_file, kaggle_file)\n",
    "    test_data = pd.read_csv(kaggle_file)\n",
    "    test_data['Survived'] = test_data['PassengerId'].apply(lambda x : pid_to_survived.get(x))\n",
    "    test_data.to_csv(new_output_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 : Use Sex alone as a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_and_stats(X, Y, size_test_set=0.25, num_folds_cv=5):\n",
    "    X_train, X_test, Y_train, Y_test = \\\n",
    "        train_test_split(X, Y, test_size=size_test_set, random_state=0)\n",
    "    logistic = linear_model.LogisticRegression()\n",
    "    \n",
    "\n",
    "    # Make pipeline here to take care of imputations.\n",
    "    my_pipeline = make_pipeline(Imputer(), linear_model.LogisticRegression())\n",
    "\n",
    "    starting_model = my_pipeline.fit(X_train, Y_train)\n",
    "    \n",
    "    print(\"Length of full training set is \", len(X))\n",
    "    print(\"Length of used training set is \", len(X_train))    \n",
    "    print(\"Length of used test set is \", len(X_test))        \n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    scores = cross_val_score(my_pipeline, X_train, Y_train, cv=num_folds_cv)    \n",
    "    print(\"Number of correct predictions on used training data   is \", \n",
    "          starting_model.score(X_train, Y_train) * len(X_train))\n",
    "    print(\"Number of correct predictions on used test data   is \", \n",
    "          starting_model.score(X_test, Y_test) * len(X_test))\n",
    "\n",
    "    return (starting_model, \n",
    "            starting_model.score(X_train, Y_train),  \n",
    "            np.mean(scores), \n",
    "            starting_model.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "def display_manual_model_metrics(test_v1, message):\n",
    "    print(\"Fit score obtained  :\" + message, \n",
    "          np.sum((test_v1['Survived'] == test_v1['Predictions'])/len(\n",
    "              test_v1['Survived'])))\n",
    "    print(\"Number of correct entries  :\" + message, \n",
    "          np.sum((test_v1['Survived'] == test_v1['Predictions'])))\n",
    "    print(\"Total number of  entries  :\" + message, \n",
    "          len(test_v1['Survived']))\n",
    "\n",
    "    print(\"AUC obtained  :\" + message, \n",
    "          roc_auc_score(test_v1['Survived'].apply(lambda x : int(x)),\n",
    "                        test_v1['Predictions'].apply(lambda x : int(x))))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_X_Y_sex(given_data):\n",
    "    X = np.zeros(shape=(len(given_data), 1))\n",
    "    X[:,0] = pd.get_dummies(given_data['Sex'])['female']\n",
    "\n",
    "    Y = given_data['Survived'] \n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_out_of_sample_predictions(get_data_X_Y, model, test_data, generate_kaggle_file):\n",
    "    (X, Y) = get_data_X_Y(test_data)\n",
    "    test_data.loc[:,'Predictions'] =  model.predict(X).tolist()\n",
    "    display_manual_model_metrics(test_data, '(logistic regression)')\n",
    "    if generate_kaggle_file:\n",
    "        test_data['Survived'] = test_data['Predictions']\n",
    "        test_data[['PassengerId', 'Survived']].sort_values(\n",
    "            by=['PassengerId']).to_csv(\"kaggle_out_logistic_regression.csv\", index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_given_data(train_data, get_data_X_Y, generate_out_of_sample=False, test_data=(),\n",
    "                                   generate_kaggle_file=False):\n",
    "    (X, Y) = get_data_X_Y(train_data)\n",
    "    (model, training_prediction_score, cross_val_score, test_set_score) = get_model_and_stats(X, Y)\n",
    "    print(\"Training Prediction score is {2} \\nCross validated measure is {0} \\nTest set measures is {1}\".format(\n",
    "        cross_val_score, test_set_score, training_prediction_score))\n",
    "\n",
    "    if generate_out_of_sample:\n",
    "        generate_out_of_sample_predictions(get_data_X_Y, model, test_data, generate_kaggle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of full training set is  891\n",
      "Length of used training set is  668\n",
      "Length of used test set is  223\n",
      "Number of correct predictions on used training data   is  527.0\n",
      "Number of correct predictions on used test data   is  174.0\n",
      "Training Prediction score is 0.7889221556886228 \n",
      "Cross validated measure is 0.7889462462125463 \n",
      "Test set measures is 0.7802690582959642\n"
     ]
    }
   ],
   "source": [
    "train_validate_test_given_data(train_data, get_data_X_Y_sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 : Use Sex,  Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_X_Y_sex_pclass(given_data):\n",
    "    X = np.zeros(shape=(len(given_data), 3))\n",
    "    X[:,0] = pd.get_dummies(given_data['Sex'])['female']\n",
    "    X[:,1] = pd.get_dummies(given_data['Pclass'])[1]\n",
    "    X[:,2] = pd.get_dummies(given_data['Pclass'])[2]\n",
    "\n",
    "    Y = given_data['Survived'] \n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of full training set is  891\n",
      "Length of used training set is  668\n",
      "Length of used test set is  223\n",
      "Number of correct predictions on used training data   is  527.0\n",
      "Number of correct predictions on used test data   is  174.0\n",
      "Training Prediction score is 0.7889221556886228 \n",
      "Cross validated measure is 0.7889462462125463 \n",
      "Test set measures is 0.7802690582959642\n"
     ]
    }
   ],
   "source": [
    "train_validate_test_given_data(train_data, get_data_X_Y_sex_pclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 : Use Sex, Age, Pclass (with imputation on Age column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_X_Y_sex_pclass_age(given_data):\n",
    "    X = np.zeros(shape=(len(given_data), 4))\n",
    "    X[:,0] = pd.get_dummies(given_data['Sex'])['female']\n",
    "    X[:,1] = pd.get_dummies(given_data['Pclass'])[1]\n",
    "    X[:,2] = pd.get_dummies(given_data['Pclass'])[2]\n",
    "    X[:,3] = given_data['Age']\n",
    "\n",
    "    Y = given_data['Survived'] \n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of full training set is  891\n",
      "Length of used training set is  668\n",
      "Length of used test set is  223\n",
      "Number of correct predictions on used training data   is  531.0\n",
      "Number of correct predictions on used test data   is  176.0\n",
      "Training Prediction score is 0.7949101796407185 \n",
      "Cross validated measure is 0.797946358433397 \n",
      "Test set measures is 0.7892376681614349\n"
     ]
    }
   ],
   "source": [
    "train_validate_test_given_data(train_data, get_data_X_Y_sex_pclass_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 : Use Sex, Age, Pclass, Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_X_Y_sex_pclass_age_parch(given_data):\n",
    "    X = np.zeros(shape=(len(given_data), 5))\n",
    "    X[:,0] = pd.get_dummies(given_data['Sex'])['female']\n",
    "    X[:,1] = pd.get_dummies(given_data['Pclass'])[1]\n",
    "    X[:,2] = pd.get_dummies(given_data['Pclass'])[2]\n",
    "    X[:,3] = given_data['Age']\n",
    "    X[:,4] = given_data['Parch']    \n",
    "\n",
    "    Y = given_data['Survived'] \n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of full training set is  891\n",
      "Length of used training set is  668\n",
      "Length of used test set is  223\n",
      "Number of correct predictions on used training data   is  534.0\n",
      "Number of correct predictions on used test data   is  177.0\n",
      "Training Prediction score is 0.7994011976047904 \n",
      "Cross validated measure is 0.7964313769498372 \n",
      "Test set measures is 0.7937219730941704\n"
     ]
    }
   ],
   "source": [
    "train_validate_test_given_data(train_data, get_data_X_Y_sex_pclass_age_parch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 : Use Sex, Age, Pclass, Parch, SipSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_X_Y_sex_pclass_age_parch_sibsp(given_data):\n",
    "    X = np.zeros(shape=(len(given_data), 6))\n",
    "    X[:,0] = pd.get_dummies(given_data['Sex'])['female']\n",
    "    X[:,1] = pd.get_dummies(given_data['Pclass'])[1]\n",
    "    X[:,2] = pd.get_dummies(given_data['Pclass'])[2]\n",
    "    X[:,3] = given_data['Age']\n",
    "    X[:,4] = given_data['Parch']    \n",
    "    X[:,5] = given_data['SibSp']        \n",
    "\n",
    "    Y = given_data['Survived'] \n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of full training set is  891\n",
      "Length of used training set is  668\n",
      "Length of used test set is  223\n",
      "Number of correct predictions on used training data   is  540.0\n",
      "Number of correct predictions on used test data   is  177.0\n",
      "Training Prediction score is 0.8083832335329342 \n",
      "Cross validated measure is 0.8054314891706879 \n",
      "Test set measures is 0.7937219730941704\n"
     ]
    }
   ],
   "source": [
    "train_validate_test_given_data(train_data, get_data_X_Y_sex_pclass_age_parch_sibsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6 : Use Sex, Age, Pclass, Parch, SipSp, number of family members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['FamilyNum'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['FamilyNum'] = test_data['SibSp'] + test_data['Parch'] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_X_Y_sex_pclass_age_parch_sibsp_familynum(given_data):\n",
    "    X = np.zeros(shape=(len(given_data), 7))\n",
    "    X[:,0] = pd.get_dummies(given_data['Sex'])['female']\n",
    "    X[:,1] = pd.get_dummies(given_data['Pclass'])[1]\n",
    "    X[:,2] = pd.get_dummies(given_data['Pclass'])[2]\n",
    "    X[:,3] = given_data['Age']\n",
    "    X[:,4] = given_data['Parch']    \n",
    "    X[:,5] = given_data['SibSp']        \n",
    "    X[:,6] = given_data['FamilyNum']            \n",
    "\n",
    "    Y = given_data['Survived'] \n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of full training set is  891\n",
      "Length of used training set is  668\n",
      "Length of used test set is  223\n",
      "Number of correct predictions on used training data   is  540.0\n",
      "Number of correct predictions on used test data   is  176.0\n",
      "Training Prediction score is 0.8083832335329342 \n",
      "Cross validated measure is 0.8054314891706879 \n",
      "Test set measures is 0.7892376681614349\n"
     ]
    }
   ],
   "source": [
    "train_validate_test_given_data(train_data, get_data_X_Y_sex_pclass_age_parch_sibsp_familynum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7 : Use Sex, Age, Pclass, Parch, SipSp, FamilyNum, IsAlone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['IsAlone'] = (train_data['FamilyNum'] == 1)\n",
    "test_data['IsAlone'] = (test_data['FamilyNum'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_X_Y_sex_pclass_age_parch_sibsp_familynum_isalone(given_data):\n",
    "    X = np.zeros(shape=(len(given_data), 8))\n",
    "    X[:,0] = pd.get_dummies(given_data['Sex'])['female']\n",
    "    X[:,1] = pd.get_dummies(given_data['Pclass'])[1]\n",
    "    X[:,2] = pd.get_dummies(given_data['Pclass'])[2]\n",
    "    X[:,3] = given_data['Age']\n",
    "    X[:,4] = given_data['Parch']    \n",
    "    X[:,5] = given_data['SibSp']        \n",
    "    X[:,6] = given_data['FamilyNum']      \n",
    "    X[:,7] = given_data['IsAlone']          \n",
    "\n",
    "    Y = given_data['Survived'] \n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of full training set is  891\n",
      "Length of used training set is  668\n",
      "Length of used test set is  223\n",
      "Number of correct predictions on used training data   is  541.0\n",
      "Number of correct predictions on used test data   is  176.0\n",
      "Training Prediction score is 0.8098802395209581 \n",
      "Cross validated measure is 0.8099315452811131 \n",
      "Test set measures is 0.7892376681614349\n"
     ]
    }
   ],
   "source": [
    "train_validate_test_given_data(train_data, get_data_X_Y_sex_pclass_age_parch_sibsp_familynum_isalone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 8 : Use Sex, Age, Pclass, Parch, SipSp, FamilyNum, IsAlone, FarePerPerson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['FarePerPerson'] = train_data['Fare']/train_data['FamilyNum']\n",
    "test_data['FarePerPerson'] = test_data['Fare']/test_data['FamilyNum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_data_X_Y_sex_pclass_age_parch_sibsp_familynum_isalone_fare(given_data):\n",
    "    X = np.zeros(shape=(len(given_data), 9))\n",
    "    X[:,0] = pd.get_dummies(given_data['Sex'])['female']\n",
    "    X[:,1] = pd.get_dummies(given_data['Pclass'])[1]\n",
    "    X[:,2] = pd.get_dummies(given_data['Pclass'])[2]\n",
    "    X[:,3] = given_data['Age']\n",
    "    X[:,4] = given_data['Parch']    \n",
    "    X[:,5] = given_data['SibSp']        \n",
    "    X[:,6] = given_data['FamilyNum']      \n",
    "    X[:,7] = given_data['IsAlone']        \n",
    "    X[:,8] = given_data['FarePerPerson']            \n",
    "\n",
    "    Y = given_data['Survived'] \n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of full training set is  891\n",
      "Length of used training set is  668\n",
      "Length of used test set is  223\n",
      "Number of correct predictions on used training data   is  540.0\n",
      "Number of correct predictions on used test data   is  176.0\n",
      "Training Prediction score is 0.8083832335329342 \n",
      "Cross validated measure is 0.8084390079676803 \n",
      "Test set measures is 0.7892376681614349\n"
     ]
    }
   ],
   "source": [
    "train_validate_test_given_data(train_data, get_data_X_Y_sex_pclass_age_parch_sibsp_familynum_isalone_fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "It is slightly tricky here, but given our preference for simpler models and since the increase in cross validation score is little, we will go with Model 5 (and see how it performs on the out of sample data as  well as generate an output file for kaggle as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of full training set is  891\n",
      "Length of used training set is  668\n",
      "Length of used test set is  223\n",
      "Number of correct predictions on used training data   is  540.0\n",
      "Number of correct predictions on used test data   is  177.0\n",
      "Training Prediction score is 0.8083832335329342 \n",
      "Cross validated measure is 0.8054314891706879 \n",
      "Test set measures is 0.7937219730941704\n",
      "Fit score obtained  :(logistic regression) 0.763157894736842\n",
      "Number of correct entries  :(logistic regression) 319\n",
      "Total number of  entries  :(logistic regression) 418\n",
      "AUC obtained  :(logistic regression) 0.7438169425511197\n"
     ]
    }
   ],
   "source": [
    "train_validate_test_given_data(train_data, get_data_X_Y_sex_pclass_age_parch_sibsp, \n",
    "                               True, test_data, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
